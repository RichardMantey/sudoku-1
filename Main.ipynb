{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import copy\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "# from Downloads import LSTMSudokuClassifier as LSTMC\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, n_timeSteps, hidden_dim, label_size, batch_size,nLayers, use_gpu):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.use_gpu = use_gpu\n",
    "        self.n_timeSteps = n_timeSteps\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, nLayers)\n",
    "        self.hidden2label = nn.Sequential(torch.nn.Linear(hidden_dim,label_size),\n",
    "                            torch.nn.Softmax(dim = -1))\n",
    "        self.hidden = self.init_hidden()\n",
    "\n",
    "    def init_hidden(self):\n",
    "        if self.use_gpu:\n",
    "            h0 = Variable(torch.zeros(nLayers, self.batch_size, self.hidden_dim).cuda())\n",
    "            c0 = Variable(torch.zeros(nLayers, self.batch_size, self.hidden_dim).cuda())\n",
    "        else:\n",
    "            h0 = Variable(torch.zeros(nLayers, self.batch_size, self.hidden_dim))\n",
    "            c0 = Variable(torch.zeros(nLayers, self.batch_size, self.hidden_dim))\n",
    "        return (h0, c0)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = inputs.view(self.n_timeSteps, batch_size, input_dim) \n",
    "        lstm_out, self.hidden = self.lstm(x, self.hidden)\n",
    "        last_output = lstm_out[-1]\n",
    "#         print(last_output)\n",
    "        y  = self.hidden2label(lstm_out[-1])\n",
    "        return y\n",
    "\n",
    "class InputGrid():\n",
    "    \n",
    "    def __init__(self, Grid, gridLength, batch_size):\n",
    "        self.Grid =  Grid\n",
    "        self.gridLength = gridLength      \n",
    "        self.batchSize = batch_size\n",
    "        \n",
    "    def getlims(self, i):\n",
    "        if 0 <= i <= 2:\n",
    "            rowlims = [0,3]\n",
    "        elif 3 <= i <= 5:\n",
    "            rowlims = [3,6]\n",
    "        elif 6 <= i <= 8:\n",
    "                rowlims = [6,9]\n",
    "        return rowlims\n",
    "\n",
    "    def getSquare(squareRow,squareCol,k):\n",
    "        box=[]\n",
    "        for i in range(squareRow[0],squareRow[1]):\n",
    "            for j in range(squareCol[0],squareCol[1]):\n",
    "                box.append(Grid[k,i,j])\n",
    "        return box\n",
    "\n",
    "    def getBestInput(row,col,square):\n",
    "        nZeros = np.sum([(row == 0).sum(),(col == 0).sum(),(square ==0).sum()])-3\n",
    "        return nZeros \n",
    "    \n",
    "    def getInput(self):\n",
    "        Batch = []\n",
    "        Indices = []\n",
    "        Update = []\n",
    "        for k in range(batchSize):\n",
    "            Final = []\n",
    "            Index = []\n",
    "            update = 0\n",
    "            minZeros = gridLength\n",
    "            for i in range(gridLength):\n",
    "                for j in range(gridLength):\n",
    "                    if Grid[k,i,j] == 0:\n",
    "                        row = Grid[k,i,:]\n",
    "                        col = Grid[k,:,j]\n",
    "                        squareRow = getlims(i)\n",
    "                        squareCol = getlims(j)\n",
    "                        square = np.array(getSquare(squareRow,squareCol,k))\n",
    "                        nZeros = getBestInput(row,col,square)\n",
    "                        if nZeros < minZeros:\n",
    "                            Final = [row,col,square]\n",
    "                            Index = [k,i,j]\n",
    "                            update = 1\n",
    "                            minZeros = nZeros    \n",
    "        #                 print(Final,Index,update)\n",
    "        #                 print('*****************')\n",
    "\n",
    "\n",
    "            if len(Final) == 0:\n",
    "                i = randint(0,8)\n",
    "                j = randint(0,8)\n",
    "                row = Grid[k,i,:]\n",
    "                col = Grid[k,:,j]\n",
    "                squareRow = getlims(i)\n",
    "                squareCol = getlims(j)\n",
    "                square = np.array(getSquare(squareRow,squareCol,k))\n",
    "                Final = [row,col,square]\n",
    "                Index = [k,i,j]\n",
    "                update = 0\n",
    "                \n",
    "#             print(Final,Index,update)\n",
    "#             print('*****************')\n",
    "            Batch.append(Final)\n",
    "            Indices.append(Index)\n",
    "            Update.append(update)\n",
    "            \n",
    "#         print(Batch)\n",
    "#         print('*****************')\n",
    "#         print(Indices)\n",
    "#         print('*****************')\n",
    "#         print(Update)\n",
    "#         print('*****************')\n",
    "\n",
    "        inputs = [Variable(torch.FloatTensor(line)) for final in Batch for line in final]\n",
    "        inputs = torch.cat(inputs).view(3, batchSize, -1)\n",
    "        print(inputs)\n",
    "        print(inputs.shape)\n",
    "        \n",
    "        return inputs, Indices, Update\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "use_plot = True\n",
    "use_save = True\n",
    "if use_save:\n",
    "    import pickle\n",
    "    from datetime import datetime\n",
    "\n",
    "DATA_DIR = 'data'\n",
    "TRAIN_DIR = 'train_txt'\n",
    "TEST_DIR = 'test_txt'\n",
    "TRAIN_FILE = 'train_txt.txt'\n",
    "TEST_FILE = 'test_txt.txt'\n",
    "TRAIN_LABEL = 'train_label.txt'\n",
    "TEST_LABEL = 'test_label.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## parameter setting\n",
    "epochs = 50\n",
    "batch_size = 1\n",
    "use_gpu = torch.cuda.is_available()\n",
    "learning_rate = 0.01\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    lr = learning_rate * (0.1 ** (epoch // 10))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__=='__main__':\n",
    "    ### parameter setting\n",
    "    input_dim = 9\n",
    "    hidden_dim = 50\n",
    "    sentence_len = 3\n",
    "    nlabel = 9\n",
    "    nLayers = 3\n",
    "    \n",
    "#     train_file = os.path.join(DATA_DIR, TRAIN_FILE)\n",
    "#     test_file = os.path.join(DATA_DIR, TEST_FILE)\n",
    "#     fp_train = open(train_file, 'r')\n",
    "#     train_filenames = [os.path.join(TRAIN_DIR, line.strip()) for line in fp_train]\n",
    "#     filenames = copy.deepcopy(train_filenames)\n",
    "#     fp_train.close()\n",
    "#     fp_test = open(test_file, 'r')\n",
    "#     test_filenames = [os.path.join(TEST_DIR, line.strip()) for line in fp_test]\n",
    "#     fp_test.close()\n",
    "#     filenames.extend(test_filenames)\n",
    "\n",
    "#     corpus = DP.Corpus(DATA_DIR, filenames)\n",
    "#***************************PlaceholdingBreak***************************\n",
    "     ### ********************create model**************************\n",
    "    model = LSTMClassifier(input_dim, sentence_len, hidden_dim,\n",
    "                           nlabel, batch_size, nLayers, use_gpu)\n",
    "    if use_gpu:\n",
    "        model = model.cuda()\n",
    "        \n",
    "    ### data processing\n",
    "#     dtrain_set = DP.TxtDatasetProcessing(DATA_DIR, TRAIN_DIR, TRAIN_FILE, TRAIN_LABEL, sentence_len, corpus)\n",
    "\n",
    "#     train_loader = DataLoader(dtrain_set,\n",
    "#                           batch_size=batch_size,\n",
    "#                           shuffle=True,\n",
    "#                           num_workers=4\n",
    "#                          )\n",
    "#     dtest_set = DP.TxtDatasetProcessing(DATA_DIR, TEST_DIR, TEST_FILE, TEST_LABEL, sentence_len, corpus)\n",
    "\n",
    "#     test_loader = DataLoader(dtest_set,\n",
    "#                           batch_size=batch_size,\n",
    "#                           shuffle=False,\n",
    "#                           num_workers=4\n",
    "#                          )\n",
    "\n",
    "#***************************PlaceholdingBreak***************************\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "    train_loss_ = []\n",
    "    test_loss_ = []\n",
    "    train_acc_ = []\n",
    "    test_acc_ = []\n",
    "#***************************PlaceholdingBreak***************************\n",
    "### training procedure\n",
    "\n",
    "#********************Fake Train and Test loader*************************************\n",
    "    n_boxes = 2\n",
    "    inputs = [Variable(torch.FloatTensor(np.random.permutation(range(1,10))))\\\n",
    "      for _ in range(sentence_len)]\n",
    "\n",
    "    test = [Variable(torch.FloatTensor(np.random.permutation(range(1,10))))\\\n",
    "      for _ in range(sentence_len)]\n",
    "\n",
    "    inputs = torch.cat(inputs).view(sentence_len, 1, -1)\n",
    "    test = torch.cat(test).view(sentence_len, 1, -1)\n",
    "    target = Variable(torch.LongTensor(n_boxes).random_(1, 9))\n",
    "    train_loader = target[0],inputs #real soln value, row,col,box at that index\n",
    "    test_loader = target[1],test\n",
    "    \n",
    "    inputGrid = InputGrid(Grid,gridLength)\n",
    "    \n",
    "#         print(train_loader)\n",
    "\n",
    "#*************************************************************************\n",
    "\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        optimizer = adjust_learning_rate(optimizer, epoch)\n",
    "\n",
    "        ## training epoch\n",
    "        total_acc = 0.0\n",
    "        total_loss = 0.0\n",
    "        total = 0.0\n",
    "        \n",
    "        for puzzle,\n",
    "        #First for loop over all Problems/Solutions here \n",
    "        \n",
    "        #Insert first grid here - Our trainloader will be [3*1*9 row,col,box inputs],corresponding solution entries\n",
    "        #Consider switching to for n(0s), \n",
    "            #run zero selecting algorithm to extract the row column, box values\n",
    "            #return index and use that to grab corresponding label\n",
    "            #train inputs,labels = those values\n",
    "            \n",
    "            \n",
    "#         for iter, traindata in enumerate(train_loader): \n",
    "        train_inputs, train_labels = inputs,target[0]\n",
    "        #train_labels = torch.squeeze(train_labels)\n",
    "#         print(train_inputs)\n",
    "            \n",
    "#### For real Data, need to wrap as \n",
    "            #if use_gpu:\n",
    "#                 train_inputs, train_labels = Variable(train_inputs.cuda()), train_labels.cuda()\n",
    "#             else: train_inputs = Variable(train_inputs)\n",
    "\n",
    "\n",
    "        if use_gpu:\n",
    "            train_inputs, train_labels = train_inputs.cuda(), train_labels.cuda()\n",
    "        else: train_inputs = train_inputs\n",
    "\n",
    "        model.zero_grad()\n",
    "        model.batch_size = len(train_labels) #should be one\n",
    "        model.hidden = model.init_hidden()\n",
    "        output = model(train_inputs)\n",
    "\n",
    "        #could consider adding up the losses and doing backprop after each puzzle\n",
    "        loss = loss_function(output, train_labels)\n",
    "\n",
    "        #Could consider pushing both of these outside the loop and running after each puzzle\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        #****************************Break***********************\n",
    "        #Update the grid here\n",
    "        #***************************Break*************************\n",
    "\n",
    "        # calc training acc\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        print('TrainPred =  ',predicted, 'While TrainLabel = ' ,train_labels.data)\n",
    "        total_acc += (predicted == train_labels.data).sum()\n",
    "        total += len(train_labels)\n",
    "        total_loss += loss.data[0]\n",
    "            \n",
    "      \n",
    "        train_loss_.append(total_loss / total)\n",
    "        train_acc_.append(total_acc / total)\n",
    "        \n",
    "        \n",
    "        #****************************Will need to be outside training forloop************\n",
    "        #First for loop over all Problems/Solutions here \n",
    "        \n",
    "        #Insert first grid here - Our testloader will be [3*1*9 row,col,box inputs],corresponding solution entries\n",
    "        #Consider switching to for n(0s), \n",
    "            #run zero selecting algorithm to extract the row column, box values\n",
    "            #return index and use that to grab corresponding label\n",
    "            #train inputs,labels = those values = testloader\n",
    "            \n",
    "        ## testing epoch\n",
    "        total_acc = 0.0\n",
    "        total_loss = 0.0\n",
    "        total = 0.0\n",
    "        \n",
    "        \n",
    "        \n",
    "#         for iter, testdata in enumerate(test_loader):\n",
    "        test_inputs, test_labels = test,target[1],\n",
    "#             test_labels = torch.squeeze(test_labels)\n",
    "\n",
    "\n",
    "        #### For real Data, need to wrap as \n",
    "        #if use_gpu:\n",
    "#                 train_inputs, train_labels = Variable(train_inputs.cuda()), train_labels.cuda()\n",
    "#             else: train_inputs = Variable(train_inputs)\n",
    "\n",
    "        if use_gpu:\n",
    "            test_inputs, test_labels = test_inputs.cuda(), test_labels.cuda()\n",
    "        else: test_inputs = test_inputs\n",
    "\n",
    "        model.batch_size = len(test_labels)\n",
    "        model.hidden = model.init_hidden()\n",
    "        output = model(test_inputs.t())\n",
    "\n",
    "        loss = loss_function(output, test_labels)\n",
    "\n",
    "        # calc testing acc\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        print('TestPred = ',predicted, 'While TestLabel = ' ,test_labels.data)\n",
    "        total_acc += (predicted == test_labels.data).sum()\n",
    "        total += len(test_labels)\n",
    "        total_loss += loss.data[0]\n",
    "        \n",
    "        \n",
    "        \n",
    "        test_loss_.append(total_loss / total)\n",
    "        test_acc_.append(total_acc / total)\n",
    "\n",
    "        print('[Epoch: %3d/%3d] Training Loss: %.3f, Testing Loss: %.3f, Training Acc: %.3f, Testing Acc: %.3f'\n",
    "              % (epoch, epochs, train_loss_[epoch], test_loss_[epoch], train_acc_[epoch], test_acc_[epoch]))\n",
    "\n",
    "    param = {}\n",
    "    param['lr'] = learning_rate\n",
    "    param['batch size'] = batch_size\n",
    "    param['input dim'] = input_dim\n",
    "    param['hidden dim'] = hidden_dim\n",
    "    param['nTimeSteps'] = sentence_len\n",
    "\n",
    "    result = {}\n",
    "    result['train loss'] = train_loss_\n",
    "    result['test loss'] = test_loss_\n",
    "    result['train acc'] = train_acc_\n",
    "    result['test acc'] = test_acc_\n",
    "    result['param'] = param\n",
    "\n",
    "    if use_plot:\n",
    "        import PlotFigure as PF\n",
    "        PF.PlotFigure(result, use_save)\n",
    "    if use_save:\n",
    "        filename = 'log/LSTM_classifier_' + datetime.now().strftime(\"%d-%h-%m-%s\") + '.pkl'\n",
    "        result['filename'] = filename\n",
    "\n",
    "        fp = open(filename, 'wb')\n",
    "        pickle.dump(result, fp)\n",
    "        fp.close()\n",
    "        print('File %s is saved.' % filename)      \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
