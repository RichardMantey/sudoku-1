{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import copy\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import Dataset\n",
    "# from Downloads import LSTMSudokuClassifier as LSTMC\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, n_features, hidden_dim, n_label, batch_size, n_layers, use_gpu):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.use_gpu = use_gpu\n",
    "        self.n_features = n_features\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, n_layers, bidirectional=True)\n",
    "        self.hidden2label = nn.Sequential(torch.nn.Linear(2*hidden_dim, n_label),\n",
    "                            torch.nn.Softmax(dim = -1))\n",
    "        self.hidden = self.init_hidden()\n",
    "\n",
    "    def init_hidden(self):\n",
    "        if self.use_gpu:\n",
    "            h0 = Variable(torch.zeros(2*n_layers, self.batch_size, self.hidden_dim).cuda())\n",
    "            c0 = Variable(torch.zeros(2*n_layers, self.batch_size, self.hidden_dim).cuda())\n",
    "        else:\n",
    "            h0 = Variable(torch.zeros(n_layers, self.batch_size, self.hidden_dim))\n",
    "            c0 = Variable(torch.zeros(n_layers, self.batch_size, self.hidden_dim))\n",
    "        return (h0, c0)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = inputs.view(self.n_features, self.batch_size, self.input_dim) \n",
    "        lstm_out, self.hidden = self.lstm(x, self.hidden)\n",
    "        last_output = lstm_out[-1]\n",
    "        print(last_output.shape)\n",
    "        y  = self.hidden2label(lstm_out[-1])\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class InputGrid():\n",
    "    \n",
    "    def __init__(self, Grid, batch_size):\n",
    "        self.Grid = Grid\n",
    "        self.gridLength = len(Grid[0])\n",
    "        self.batchSize = batch_size\n",
    "        \n",
    "    def getlims(self, i):\n",
    "        if 0 <= i <= 2:\n",
    "            rowlims = [0,3]\n",
    "        elif 3 <= i <= 5:\n",
    "            rowlims = [3,6]\n",
    "        elif 6 <= i <= 8:\n",
    "                rowlims = [6,9]\n",
    "        return rowlims\n",
    "\n",
    "    def getSquare(self, squareRow, squareCol, k):\n",
    "        box=[]\n",
    "        for i in range(squareRow[0],squareRow[1]):\n",
    "            for j in range(squareCol[0],squareCol[1]):\n",
    "                box.append(self.Grid[k,i,j])\n",
    "        return box\n",
    "    \n",
    "    # takes 1D returns 2D\n",
    "    def one_hot(vec):\n",
    "        for val in vec:\n",
    "            \n",
    "    \n",
    "    def getInput(self):\n",
    "        Rows = []\n",
    "        Columns = []\n",
    "        Squares = []\n",
    "        for k in range(self.batchSize):\n",
    "            rows = []\n",
    "            column = []\n",
    "            square = []\n",
    "            for i in range(self.gridLength):\n",
    "                for j in range(self.gridLength):\n",
    "                    g_row = self.Grid[k,i,:]\n",
    "                 \n",
    "        return inputs, Indices, Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "use_plot = True\n",
    "use_save = True\n",
    "# if use_save:\n",
    "#     import pickle\n",
    "#     from datetime import datetime\n",
    "\n",
    "DATA_DIR = 'data'\n",
    "TRAIN_FILE = 'sudoku_dev.csv'\n",
    "TEST_FILE = 'sudoku_test.txt'\n",
    "TRAIN_LABEL = 'train_label.txt'\n",
    "TEST_LABEL = 'test_label.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SudokuDataset(Dataset):\n",
    "    def __init__(self, fpath):\n",
    "        \n",
    "        print(fpath)\n",
    "        lines = open(fpath, 'r').read().splitlines()[1:]\n",
    "        nsamples = len(lines)\n",
    "\n",
    "        X = np.zeros((nsamples, 9*9), np.float32)  \n",
    "        Y = np.zeros((nsamples, 9*9), np.int32) \n",
    "\n",
    "        for i, line in enumerate(lines):\n",
    "            quiz, solution = line.split(\",\")\n",
    "            for j, (q, s) in enumerate(zip(quiz, solution)):\n",
    "                X[i, j], Y[i, j] = q, s\n",
    "\n",
    "        X = np.reshape(X, (-1, 9, 9))\n",
    "        Y = np.reshape(Y, (-1, 9, 9))\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        quiz = self.X[index]\n",
    "        sol = self.Y[index]\n",
    "        return quiz, sol\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def countZeros(batch_grid):\n",
    "    batch, row, col = batch_grid.shape\n",
    "    num_zeros = 0\n",
    "    \n",
    "    for k in range(batch):\n",
    "        for i in range(row):\n",
    "            for j in range(col):\n",
    "                if (batch_grid[k,i,j] == 0):\n",
    "                    num_zeros += 1\n",
    "                    \n",
    "    return num_zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\\sudoku_dev.csv\n",
      "3027\n",
      "torch.Size([64, 100])\n",
      "[Epoch:   0/100] Training Loss: 2.302, Training Acc: 0.094\n",
      "torch.Size([64, 100])\n",
      "[Epoch:   1/100] Training Loss: 2.302, Training Acc: 0.094\n",
      "torch.Size([64, 100])\n",
      "[Epoch:   2/100] Training Loss: 2.301, Training Acc: 0.188\n",
      "torch.Size([64, 100])\n",
      "[Epoch:   3/100] Training Loss: 2.299, Training Acc: 0.203\n",
      "torch.Size([64, 100])\n",
      "[Epoch:   4/100] Training Loss: 2.298, Training Acc: 0.172\n",
      "torch.Size([64, 100])\n",
      "[Epoch:   5/100] Training Loss: 2.296, Training Acc: 0.188\n",
      "torch.Size([64, 100])\n",
      "[Epoch:   6/100] Training Loss: 2.294, Training Acc: 0.156\n",
      "torch.Size([64, 100])\n",
      "[Epoch:   7/100] Training Loss: 2.292, Training Acc: 0.188\n",
      "torch.Size([64, 100])\n",
      "[Epoch:   8/100] Training Loss: 2.290, Training Acc: 0.203\n",
      "torch.Size([64, 100])\n",
      "[Epoch:   9/100] Training Loss: 2.287, Training Acc: 0.188\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  10/100] Training Loss: 2.284, Training Acc: 0.188\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  11/100] Training Loss: 2.280, Training Acc: 0.203\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  12/100] Training Loss: 2.276, Training Acc: 0.219\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  13/100] Training Loss: 2.272, Training Acc: 0.219\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  14/100] Training Loss: 2.268, Training Acc: 0.219\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  15/100] Training Loss: 2.264, Training Acc: 0.203\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  16/100] Training Loss: 2.261, Training Acc: 0.188\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  17/100] Training Loss: 2.257, Training Acc: 0.188\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  18/100] Training Loss: 2.253, Training Acc: 0.188\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  19/100] Training Loss: 2.247, Training Acc: 0.203\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  20/100] Training Loss: 2.240, Training Acc: 0.219\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  21/100] Training Loss: 2.231, Training Acc: 0.219\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  22/100] Training Loss: 2.219, Training Acc: 0.234\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  23/100] Training Loss: 2.206, Training Acc: 0.312\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  24/100] Training Loss: 2.197, Training Acc: 0.297\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  25/100] Training Loss: 2.195, Training Acc: 0.297\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  26/100] Training Loss: 2.196, Training Acc: 0.250\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  27/100] Training Loss: 2.191, Training Acc: 0.266\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  28/100] Training Loss: 2.178, Training Acc: 0.297\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  29/100] Training Loss: 2.159, Training Acc: 0.359\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  30/100] Training Loss: 2.139, Training Acc: 0.375\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  31/100] Training Loss: 2.128, Training Acc: 0.375\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  32/100] Training Loss: 2.136, Training Acc: 0.344\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  33/100] Training Loss: 2.154, Training Acc: 0.328\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  34/100] Training Loss: 2.165, Training Acc: 0.312\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  35/100] Training Loss: 2.173, Training Acc: 0.297\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  36/100] Training Loss: 2.179, Training Acc: 0.266\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  37/100] Training Loss: 2.179, Training Acc: 0.266\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  38/100] Training Loss: 2.173, Training Acc: 0.266\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  39/100] Training Loss: 2.163, Training Acc: 0.281\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  40/100] Training Loss: 2.149, Training Acc: 0.312\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  41/100] Training Loss: 2.136, Training Acc: 0.344\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  42/100] Training Loss: 2.135, Training Acc: 0.344\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  43/100] Training Loss: 2.140, Training Acc: 0.344\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  44/100] Training Loss: 2.142, Training Acc: 0.359\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  45/100] Training Loss: 2.145, Training Acc: 0.359\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  46/100] Training Loss: 2.154, Training Acc: 0.312\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  47/100] Training Loss: 2.163, Training Acc: 0.297\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  48/100] Training Loss: 2.169, Training Acc: 0.312\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  49/100] Training Loss: 2.167, Training Acc: 0.281\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  50/100] Training Loss: 2.162, Training Acc: 0.281\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  51/100] Training Loss: 2.160, Training Acc: 0.312\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  52/100] Training Loss: 2.159, Training Acc: 0.312\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  53/100] Training Loss: 2.153, Training Acc: 0.328\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  54/100] Training Loss: 2.142, Training Acc: 0.375\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  55/100] Training Loss: 2.125, Training Acc: 0.406\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  56/100] Training Loss: 2.111, Training Acc: 0.375\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  57/100] Training Loss: 2.095, Training Acc: 0.391\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  58/100] Training Loss: 2.085, Training Acc: 0.391\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  59/100] Training Loss: 2.088, Training Acc: 0.391\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  60/100] Training Loss: 2.100, Training Acc: 0.359\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  61/100] Training Loss: 2.118, Training Acc: 0.328\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  62/100] Training Loss: 2.127, Training Acc: 0.328\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  63/100] Training Loss: 2.135, Training Acc: 0.312\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  64/100] Training Loss: 2.142, Training Acc: 0.312\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  65/100] Training Loss: 2.146, Training Acc: 0.312\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  66/100] Training Loss: 2.153, Training Acc: 0.312\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  67/100] Training Loss: 2.164, Training Acc: 0.297\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  68/100] Training Loss: 2.173, Training Acc: 0.281\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  69/100] Training Loss: 2.179, Training Acc: 0.281\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  70/100] Training Loss: 2.185, Training Acc: 0.266\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  71/100] Training Loss: 2.187, Training Acc: 0.266\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  72/100] Training Loss: 2.187, Training Acc: 0.266\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  73/100] Training Loss: 2.184, Training Acc: 0.281\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  74/100] Training Loss: 2.180, Training Acc: 0.297\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  75/100] Training Loss: 2.176, Training Acc: 0.297\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  76/100] Training Loss: 2.173, Training Acc: 0.297\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  77/100] Training Loss: 2.170, Training Acc: 0.297\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  78/100] Training Loss: 2.168, Training Acc: 0.297\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  79/100] Training Loss: 2.166, Training Acc: 0.297\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  80/100] Training Loss: 2.164, Training Acc: 0.297\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  81/100] Training Loss: 2.162, Training Acc: 0.297\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  82/100] Training Loss: 2.160, Training Acc: 0.297\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  83/100] Training Loss: 2.157, Training Acc: 0.297\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  84/100] Training Loss: 2.153, Training Acc: 0.297\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  85/100] Training Loss: 2.149, Training Acc: 0.312\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  86/100] Training Loss: 2.145, Training Acc: 0.312\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  87/100] Training Loss: 2.141, Training Acc: 0.312\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  88/100] Training Loss: 2.138, Training Acc: 0.312\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  89/100] Training Loss: 2.136, Training Acc: 0.312\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  90/100] Training Loss: 2.136, Training Acc: 0.312\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  91/100] Training Loss: 2.133, Training Acc: 0.312\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  92/100] Training Loss: 2.132, Training Acc: 0.312\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  93/100] Training Loss: 2.131, Training Acc: 0.297\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  94/100] Training Loss: 2.132, Training Acc: 0.297\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  95/100] Training Loss: 2.134, Training Acc: 0.297\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  96/100] Training Loss: 2.136, Training Acc: 0.297\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  97/100] Training Loss: 2.134, Training Acc: 0.312\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  98/100] Training Loss: 2.131, Training Acc: 0.312\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  99/100] Training Loss: 2.129, Training Acc: 0.328\n",
      "updating table...\n",
      "torch.Size([64, 100])\n",
      "[Epoch:   0/100] Training Loss: 2.316, Training Acc: 0.109\n",
      "torch.Size([64, 100])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch:   1/100] Training Loss: 2.317, Training Acc: 0.125\n",
      "torch.Size([64, 100])\n",
      "[Epoch:   2/100] Training Loss: 2.317, Training Acc: 0.109\n",
      "torch.Size([64, 100])\n",
      "[Epoch:   3/100] Training Loss: 2.316, Training Acc: 0.109\n",
      "torch.Size([64, 100])\n",
      "[Epoch:   4/100] Training Loss: 2.313, Training Acc: 0.109\n",
      "torch.Size([64, 100])\n",
      "[Epoch:   5/100] Training Loss: 2.303, Training Acc: 0.109\n",
      "torch.Size([64, 100])\n",
      "[Epoch:   6/100] Training Loss: 2.291, Training Acc: 0.125\n",
      "torch.Size([64, 100])\n",
      "[Epoch:   7/100] Training Loss: 2.283, Training Acc: 0.141\n",
      "torch.Size([64, 100])\n",
      "[Epoch:   8/100] Training Loss: 2.283, Training Acc: 0.141\n",
      "torch.Size([64, 100])\n",
      "[Epoch:   9/100] Training Loss: 2.287, Training Acc: 0.125\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  10/100] Training Loss: 2.290, Training Acc: 0.172\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  11/100] Training Loss: 2.296, Training Acc: 0.172\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  12/100] Training Loss: 2.298, Training Acc: 0.172\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  13/100] Training Loss: 2.299, Training Acc: 0.141\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  14/100] Training Loss: 2.300, Training Acc: 0.141\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  15/100] Training Loss: 2.301, Training Acc: 0.141\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  16/100] Training Loss: 2.302, Training Acc: 0.141\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  17/100] Training Loss: 2.299, Training Acc: 0.156\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  18/100] Training Loss: 2.298, Training Acc: 0.125\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  19/100] Training Loss: 2.299, Training Acc: 0.141\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  20/100] Training Loss: 2.295, Training Acc: 0.141\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  21/100] Training Loss: 2.291, Training Acc: 0.156\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  22/100] Training Loss: 2.287, Training Acc: 0.172\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  23/100] Training Loss: 2.285, Training Acc: 0.172\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  24/100] Training Loss: 2.284, Training Acc: 0.141\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  25/100] Training Loss: 2.283, Training Acc: 0.156\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  26/100] Training Loss: 2.281, Training Acc: 0.141\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  27/100] Training Loss: 2.280, Training Acc: 0.156\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  28/100] Training Loss: 2.277, Training Acc: 0.156\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  29/100] Training Loss: 2.273, Training Acc: 0.172\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  30/100] Training Loss: 2.269, Training Acc: 0.172\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  31/100] Training Loss: 2.265, Training Acc: 0.172\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  32/100] Training Loss: 2.263, Training Acc: 0.188\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  33/100] Training Loss: 2.261, Training Acc: 0.172\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  34/100] Training Loss: 2.257, Training Acc: 0.219\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  35/100] Training Loss: 2.253, Training Acc: 0.203\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  36/100] Training Loss: 2.253, Training Acc: 0.203\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  37/100] Training Loss: 2.253, Training Acc: 0.188\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  38/100] Training Loss: 2.255, Training Acc: 0.188\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  39/100] Training Loss: 2.258, Training Acc: 0.203\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  40/100] Training Loss: 2.257, Training Acc: 0.172\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  41/100] Training Loss: 2.256, Training Acc: 0.172\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  42/100] Training Loss: 2.256, Training Acc: 0.172\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  43/100] Training Loss: 2.255, Training Acc: 0.172\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  44/100] Training Loss: 2.253, Training Acc: 0.188\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  45/100] Training Loss: 2.251, Training Acc: 0.188\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  46/100] Training Loss: 2.248, Training Acc: 0.188\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  47/100] Training Loss: 2.246, Training Acc: 0.203\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  48/100] Training Loss: 2.244, Training Acc: 0.203\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  49/100] Training Loss: 2.243, Training Acc: 0.203\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  50/100] Training Loss: 2.241, Training Acc: 0.219\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  51/100] Training Loss: 2.239, Training Acc: 0.219\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  52/100] Training Loss: 2.236, Training Acc: 0.219\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  53/100] Training Loss: 2.232, Training Acc: 0.219\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  54/100] Training Loss: 2.230, Training Acc: 0.234\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  55/100] Training Loss: 2.228, Training Acc: 0.250\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  56/100] Training Loss: 2.226, Training Acc: 0.250\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  57/100] Training Loss: 2.224, Training Acc: 0.250\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  58/100] Training Loss: 2.222, Training Acc: 0.266\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  59/100] Training Loss: 2.218, Training Acc: 0.312\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  60/100] Training Loss: 2.215, Training Acc: 0.312\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  61/100] Training Loss: 2.214, Training Acc: 0.328\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  62/100] Training Loss: 2.214, Training Acc: 0.312\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  63/100] Training Loss: 2.217, Training Acc: 0.281\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  64/100] Training Loss: 2.218, Training Acc: 0.297\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  65/100] Training Loss: 2.220, Training Acc: 0.297\n",
      "torch.Size([64, 100])\n",
      "[Epoch:  66/100] Training Loss: 2.220, Training Acc: 0.281\n",
      "torch.Size([64, 100])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-3be75b47b9b1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m                 \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\autograd\\variable.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[0;32m    165\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m         \"\"\"\n\u001b[1;32m--> 167\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m---> 99\u001b[1;33m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    \n",
    "    ## parameter setting\n",
    "    epochs = 100\n",
    "    batch_size = 64\n",
    "    use_gpu = torch.cuda.is_available()\n",
    "    learning_rate = 1e-3\n",
    "\n",
    "    input_dim = 9\n",
    "    hidden_dim = 50\n",
    "    n_features = 3\n",
    "    n_label = 10\n",
    "    n_layers = 3\n",
    "    \n",
    "    train_path = os.path.join(DATA_DIR, TRAIN_FILE)\n",
    "    test_path = os.path.join(DATA_DIR, TEST_FILE)\n",
    "\n",
    "\n",
    "     ### ********************create model**************************\n",
    "    model = LSTMClassifier(input_dim, n_features, hidden_dim, n_label, batch_size, n_layers, use_gpu)\n",
    "    if use_gpu:\n",
    "        model = model.cuda()\n",
    "    \n",
    "    training_set = SudokuDataset(train_path)\n",
    "    train_loader = DataLoader(training_set,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          num_workers=0\n",
    "                          )\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "    train_loss_ = []\n",
    "    test_loss_ = []\n",
    "    train_acc_ = []\n",
    "    test_acc_ = []\n",
    "    \n",
    "### training procedure\n",
    "    for iter, traindata in enumerate(train_loader):\n",
    "#         print(\"new data batch\")\n",
    "        train_inputs_raw, train_labels_raw = traindata\n",
    "\n",
    "        train_data_numpy = Variable(train_inputs_raw).data.numpy()\n",
    "        train_label_numpy = Variable(train_labels_raw).data.numpy()\n",
    "#         print(train_data_numpy.shape, train_label_numpy.shape)\n",
    "        num_zeros = countZeros(train_inputs_raw)\n",
    "        print(num_zeros)\n",
    "        cur_batch_size = train_data_numpy.shape[0]\n",
    "    \n",
    "        for cell in range(input_dim*input_dim): # max num zeros\n",
    "#             print(\"working on cell:\", cell)\n",
    "            cur_batch_size = train_data_numpy.shape[0]\n",
    "\n",
    "             = InputGrid(train_data_numpy, cur_batch_size)\n",
    "            train_inputs, indices, updates = input_grid.getInput()\n",
    "\n",
    "            train_labels = []\n",
    "            for ind,index in enumerate(indices):\n",
    "                k,i,j = index\n",
    "                train_labels.append(int(train_label_numpy[k,i,j]))\n",
    "            train_labels = Variable(torch.LongTensor(train_labels))\n",
    "            \n",
    "            total_acc = 0.0\n",
    "            total_loss = 0.0\n",
    "            total = 0.0\n",
    "\n",
    "            for epoch in range(epochs):\n",
    "#                 optimizer = adjust_learning_rate(optimizer, epoch)\n",
    "\n",
    "#                 ## training epoch\n",
    "#                 total_acc = 0.0\n",
    "#                 total_loss = 0.0\n",
    "#                 total = 0.0\n",
    "\n",
    "                if use_gpu:\n",
    "                    train_inputs, train_labels = train_inputs.cuda(), train_labels.cuda()\n",
    "                else: train_inputs = train_inputs\n",
    "\n",
    "                model.zero_grad()\n",
    "                model.batch_size = len(train_labels)\n",
    "#                 model.hidden = model.init_hidden()\n",
    "                output = model(train_inputs)\n",
    "\n",
    "                loss = loss_function(output, train_labels)\n",
    "                loss.backward(retain_graph=True)\n",
    "                optimizer.step()\n",
    "\n",
    "                # calc training acc\n",
    "                _, predicted = torch.max(output.data, 1)\n",
    "#                 print('TrainPred =  ',predicted, 'While TrainLabel = ' ,train_labels.data)\n",
    "                total_acc = (predicted == train_labels.data).sum()/len(train_labels)\n",
    "                total += len(train_labels)\n",
    "                total_loss += loss.data[0]\n",
    "                \n",
    "#                 print(\"loss:\", loss.data[0], \"acc\", total_acc)\n",
    "                \n",
    "                \n",
    "#                 train_loss_.append(total_loss / total)\n",
    "#                 train_acc_.append(total_acc / total)\n",
    "\n",
    "                print('[Epoch: %3d/%3d] Training Loss: %.3f, Training Acc: %.3f' \n",
    "                      % (epoch, epochs, loss.data[0], total_acc))\n",
    "            \n",
    "            # update with new prediction\n",
    "            print(\"updating table...\")\n",
    "#             print(\"b\", train_data_numpy)\n",
    "            for iter,index in enumerate(indices):\n",
    "                if (updates[iter]):\n",
    "                    k,i,j = index\n",
    "                    train_data_numpy[k,i,j] = train_labels[iter]\n",
    "#             print(\"a\", train_data_numpy)\n",
    "        \n",
    "        \n",
    "        #****************************Will need to be outside training forloop************\n",
    "        #First for loop over all Problems/Solutions here \n",
    "        \n",
    "        #Insert first grid here - Our testloader will be [3*1*9 row,col,box inputs],corresponding solution entries\n",
    "        #Consider switching to for n(0s), \n",
    "            #run zero selecting algorithm to extract the row column, box values\n",
    "            #return index and use that to grab corresponding label\n",
    "            #train inputs,labels = those values = testloader\n",
    "            \n",
    "\n",
    "#     param = {}\n",
    "#     param['lr'] = learning_rate\n",
    "#     param['batch_size'] = batch_size\n",
    "#     param['input_dim'] = input_dim\n",
    "#     param['hidden_dim'] = hidden_dim\n",
    "#     param['n_features'] = n_features\n",
    "\n",
    "#     result = {}\n",
    "#     result['train_loss'] = train_loss_\n",
    "# #     result['test_loss'] = test_loss_\n",
    "#     result['train_acc'] = train_acc_\n",
    "# #     result['test_acc'] = test_acc_\n",
    "#     result['param'] = param\n",
    "\n",
    "#     if use_plot:\n",
    "#         import PlotFigure as PF\n",
    "#         PF.PlotFigure(result, use_save)\n",
    "#     if use_save:\n",
    "#         filename = 'log/LSTM_classifier_' + datetime.now().strftime(\"%d-%h-%m-%s\") + '.pkl'\n",
    "#         result['filename'] = filename\n",
    "\n",
    "#         fp = open(filename, 'wb')\n",
    "#         pickle.dump(result, fp)\n",
    "#         fp.close()\n",
    "#         print('File %s is saved.' % filename)      \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## parameter setting\n",
    "epochs = 50\n",
    "batch_size = 1\n",
    "use_gpu = torch.cuda.is_available()\n",
    "learning_rate = 0.01\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    lr = learning_rate * (0.1 ** (epoch // 10))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
